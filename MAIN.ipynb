{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband, BayesianOptimization\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_file = open(\"circuits.csv\")\n",
    "circuits = list(list())\n",
    "for i in circuits_file.readlines():\n",
    "    circuits.append(i.strip().split(','))\n",
    "races_file = open(\"races.csv\")\n",
    "races = list(list())\n",
    "for i in races_file.readlines():\n",
    "    races.append(i.strip().split(','))\n",
    "qualifying_file = open(\"qualifying.csv\")\n",
    "quals = list(list())\n",
    "for i in qualifying_file.readlines():\n",
    "    quals.append(i.strip().split(','))\n",
    "pit_stops_file = open(\"pit_stops.csv\")\n",
    "pit_stops = list(list())\n",
    "for i in pit_stops_file.readlines():\n",
    "    pit_stops.append(i.strip().split(','))\n",
    "pit_stops_results = list(list())\n",
    "for i in pit_stops:\n",
    "    if i[2] != \"1\":\n",
    "        for j in range(len(pit_stops_results)):\n",
    "            if pit_stops_results[j][0] == int(i[0]) and pit_stops_results[j][1] == int(i[1]):\n",
    "                pit_stops_results[j][2] += 1\n",
    "    else:\n",
    "        pit_stops_results.append([np.int(i[0]), np.int(i[1]), 1])\n",
    "parameters = list(list())\n",
    "for i in range(len(pit_stops_results)):\n",
    "    parameters.append(list())\n",
    "    parameters[i].append((np.int(races[pit_stops_results[i][0]][1]) - 1950) * 0.01)\n",
    "    parameters[i].append((np.float(circuits[int(races[pit_stops_results[i][0]][3])][5]) + 38) * 0.01)\n",
    "    parameters[i].append((np.float(circuits[int(races[pit_stops_results[i][0]][3])][6]) + 120) * 0.001)\n",
    "    parameters[i].append((np.float(circuits[int(races[pit_stops_results[i][0]][3])][7]) + 8) * 0.0001)\n",
    "    for j in range(len(quals)):\n",
    "        if j != 0 and int(quals[j][1]) == pit_stops_results[i][0] and int(quals[j][2]) == pit_stops_results[i][1]:\n",
    "            parameters[i].append(np.int(quals[j][5]) * 0.01)\n",
    "            break\n",
    "    if len(parameters[i]) < 5:\n",
    "        parameters[i].append(np.int((random.random() * 100) % 20))\n",
    "\n",
    "\n",
    "for i in range(len(pit_stops_results)):\n",
    "    del pit_stops_results[i][0:2]\n",
    "    \n",
    "parameters_train = parameters[:(len(parameters) // 7 * 6)]\n",
    "\n",
    "for i in range(len(parameters_train)):\n",
    "    parameters_train[i] = tf.convert_to_tensor(parameters_train[i], dtype=tf.float32)\n",
    "    \n",
    "parameters_test = parameters[(len(parameters) // 7 * 6):]\n",
    "\n",
    "for i in range(len(parameters_test)):\n",
    "    parameters_test[i] = tf.convert_to_tensor(parameters_test[i], dtype=tf.float32)\n",
    "\n",
    "pit_stops_train = pit_stops_results[:(len(pit_stops_results) // 7 * 6)]\n",
    "\n",
    "for i in range(len(pit_stops_train)):\n",
    "    pit_stops_train[i] = tf.convert_to_tensor(pit_stops_train[i], dtype=tf.float32)\n",
    "    \n",
    "pit_stops_test = pit_stops_results[(len(pit_stops_results) // 7 * 6):]\n",
    "\n",
    "for i in range(len(pit_stops_test)):\n",
    "    pit_stops_test[i] = tf.convert_to_tensor(pit_stops_test[i], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project test_directory\\untitled_project\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    activation_choice = hp.Choice('activation', values=['relu', 'sigmoid', 'tanh', 'elu', 'selu'])    \n",
    "    model.add(Dense(units=hp.Int('units_input',    \n",
    "                                   min_value=512,    \n",
    "                                   max_value=1024,   \n",
    "                                   step=32),\n",
    "                    input_dim=5,\n",
    "                    activation=activation_choice))\n",
    "    model.add(Dense(units=hp.Int('units_hidden',        \n",
    "                                   min_value=128,   \n",
    "                                   max_value=600,   \n",
    "                                   step=32),\n",
    "                    activation=activation_choice))   \n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', values=['adam','rmsprop','SGD']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,                \n",
    "    objective='val_accuracy', \n",
    "                              \n",
    "    max_trials=400,             \n",
    "    directory='test_directory'   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh', 'elu', 'selu'], 'ordered': False}\n",
      "units_input (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 512, 'max_value': 1024, 'step': 32, 'sampling': None}\n",
      "units_hidden (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 600, 'step': 32, 'sampling': None}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'rmsprop', 'SGD'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 400 Complete [00h 00m 02s]\n",
      "val_accuracy: 0.6205882430076599\n",
      "\n",
      "Best val_accuracy So Far: 0.6205882430076599\n",
      "Total elapsed time: 00h 13m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "parameters_train = tf.stack(parameters_train)\n",
    "pit_stops_train = tf.stack(pit_stops_train)\n",
    "tuner.search(parameters_train,             \n",
    "             pit_stops_train,               \n",
    "             batch_size=256,           \n",
    "             epochs=30,                \n",
    "             validation_split=0.2,     \n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in test_directory\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "units_input: 864\n",
      "units_hidden: 352\n",
      "optimizer: adam\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "units_input: 544\n",
      "units_hidden: 192\n",
      "optimizer: adam\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: selu\n",
      "units_input: 896\n",
      "units_hidden: 480\n",
      "optimizer: adam\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "units_input: 544\n",
      "units_hidden: 288\n",
      "optimizer: rmsprop\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: elu\n",
      "units_input: 832\n",
      "units_hidden: 544\n",
      "optimizer: rmsprop\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: sigmoid\n",
      "units_input: 928\n",
      "units_hidden: 352\n",
      "optimizer: adam\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: sigmoid\n",
      "units_input: 928\n",
      "units_hidden: 192\n",
      "optimizer: adam\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: relu\n",
      "units_input: 960\n",
      "units_hidden: 224\n",
      "optimizer: SGD\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: elu\n",
      "units_input: 992\n",
      "units_hidden: 288\n",
      "optimizer: rmsprop\n",
      "Score: 0.6205882430076599\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: sigmoid\n",
      "units_input: 992\n",
      "units_hidden: 192\n",
      "optimizer: adam\n",
      "Score: 0.6205882430076599\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=3)\n",
    "main_model = models[0]\n",
    "main_model.save('main_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 864)               5184      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 352)               304480    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 353       \n",
      "=================================================================\n",
      "Total params: 310,017\n",
      "Trainable params: 310,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4038\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 544)               3264      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 192)               104640    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 193       \n",
      "=================================================================\n",
      "Total params: 108,097\n",
      "Trainable params: 108,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.4437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danila\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4038\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 896)               5376      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 480)               430560    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 481       \n",
      "=================================================================\n",
      "Total params: 436,417\n",
      "Trainable params: 436,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters_test = tf.stack(parameters_test)\n",
    "pit_stops_test = tf.stack(pit_stops_test)\n",
    "for model in models:\n",
    "  model.summary()\n",
    "  model.evaluate(parameters_test, pit_stops_test)\n",
    "  print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
